{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "_Your Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b23f0-1217-4ec8-b87c-b949b6945de8",
   "metadata": {},
   "source": [
    "## 1\n",
    "We dealt with Backend part of SLAM. This was the backend part as we were given graph information (Vertex and edges) and we just needed to optimize it. \n",
    "The other part is Frontend of SLAM, which calculates the edges and vertices of the graph. We can get initial vertex estimation from noisy pose data, then we can use ICP to get relative transformation from the LiDAR Scan and can add those to edges. We can do similar type of things using RGB video stream by using MVG (Multi View Geometery) concepts, adding more edges. \n",
    "For loop closure edges we could\n",
    "- Use Bag of Visual Words (Bag containing of already seen frames) and see if we see a similar type of image in the video\n",
    "- Using ICP if we able to get similar point cloud again, that means there is a loop closure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad996b5-4cc1-4c93-843a-5bba5135b613",
   "metadata": {},
   "source": [
    "## 2\n",
    "Loop closure constraints are detected through the data from multiple sensors like laser sensors, etc. The robot collects the data about the environment around them, and tries to match it with an environment it has already encountered in the past. If the two environments match it means that the robot is in the same (or near) place.\n",
    "\n",
    "## 3\n",
    "Jacobian, in our case, is a 420 X 360 matrix. Jacobian is nothing but a partial derivative of the loss function, which in turn, is made from the constraints. Since each constraint involves only two poses, most of the Jacobian matrix is zero.\n",
    "For the pose graph to be fully connected, each vertex should be connected with every other vertex. It means that the robot should be able to get the idea of the environment of all vertices while standing on any of them to form constraints. This is only possible if the full trajectory is very small, which, in our case, is not. So, the pose-graph is not fully connected. We can also prove this by observing that the number of constraints (140) is much less than that required in a fully connected graph of 120 vertices (ie, 120 * (120-1) = 14280).\n",
    "\n",
    "## 4\n",
    "SLAM frontend is all about getting data from the sensor, processing it, generating constraints, etc. No optimization stuff happens in the SLAM backend.\n",
    "SLAM backend takes the preprocessed data (constraints), applies different algorithms to optimize it and get a good idea of world and robot's location.\n",
    "\n",
    "Generating odometry constraints is part of the SLAM frontend. If it's perfect (we have an \"ideal\" sensor & environment), then we don't need to optimise anything. But, since nothing is perfect, we get small noise that gets accumulated over time to create a huge difference between reality and the robot's thinking.\n",
    "For example, a difference of 1 degree is very little noise, which can easily come. It is small, but if the robot walks 10 km at this angle then it will land in a very different place from what was supposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7eee8b-cd76-4cc7-80c7-66b1214016df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
